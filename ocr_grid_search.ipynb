{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7548955a",
   "metadata": {},
   "source": [
    "# Tibetan OCR Grid Search with Quality Scoring\n",
    "\n",
    "Systematically tests OCR parameter combinations on Tibetan pecha PDFs.\n",
    "Scores results using PyBo tokenization (% valid Tibetan words).\n",
    "\n",
    "**How to use:**\n",
    "1. Run cells 1-6 in order (setup)\n",
    "2. Run cell 7 (quick test) to verify everything works\n",
    "3. Run cell 8 (full grid search) for real results\n",
    "4. Run cell 9 (analyze) to see what worked best\n",
    "\n",
    "**Phase 2 TODO:** Explore binarization parameters (block_size, c) in Utils.binarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import csv\n",
    "import json\n",
    "import signal\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "# PyBo for OCR quality scoring\n",
    "try:\n",
    "    from pybo import WordTokenizer\n",
    "    PYBO_AVAILABLE = True\n",
    "    print(\"✅ PyBo loaded for OCR quality scoring\")\n",
    "except ImportError:\n",
    "    PYBO_AVAILABLE = False\n",
    "    print(\"⚠️  PyBo not available - quality scoring disabled\")\n",
    "    print(\"   Install with: pip install git+https://github.com/OpenPecha/pybo.git\")\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path(__file__).parent if \"__file__\" in dir() else Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Import BDRC modules\n",
    "from BDRC.Data import (\n",
    "    Encoding, LineMode, TPSMode, Platform,\n",
    "    LineDetectionConfig, LayoutDetectionConfig, OCRModelConfig\n",
    ")\n",
    "from BDRC.Inference import OCRPipeline\n",
    "from BDRC.Utils import import_local_models, get_platform\n",
    "from BDRC.utils.pdf_extract import extract_images_from_pdf\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Platform: {get_platform()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5567409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "CONFIGURATION - Uncomment ONE file to process\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "# Base directory\n",
    "BASE_DIR = Path.home() / \"Documents\" / \"tibetan-ocr-app\"\n",
    "\n",
    "# Model paths (don't change)\n",
    "OCR_MODELS_DIR = BASE_DIR / \"OCRModels\"\n",
    "LINE_MODEL_PATH = BASE_DIR / \"Models\" / \"Lines\" / \"PhotiLines.onnx\"\n",
    "LAYOUT_MODEL_PATH = BASE_DIR / \"Models\" / \"Layout\" / \"photi.onnx\"\n",
    "\n",
    "# ============================================================================\n",
    "# CHOOSE ONE FILE - Uncomment exactly ONE line\n",
    "# ============================================================================\n",
    "\n",
    "# --- UCHEN HIGH QUALITY (3 files, 16 pages total) ---\n",
    "TARGET = BASE_DIR / \"input_files/tibetan_texts/uchen_high_quality_examples/uchen high quality pdf.pdf\"  # 10 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/uchen_high_quality_examples/uchen_high_quality_.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/uchen_high_quality_examples/uchen_high_quality_pdf.pdf\"  # 3 pages\n",
    "\n",
    "# --- UCHEN MEDIUM QUALITY (2 files, 7 pages total) ---\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/uchen_medium_quality_examples/uchen_medium quality.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/uchen_medium_quality_examples/uchen_medium quality(1).pdf\"  # 4 pages\n",
    "\n",
    "# --- UCHEN POOR QUALITY (3 files, 9 pages total) ---\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/uchen_poor_quality_examples/uchen_tsalyig_poor quality.pdf\"  # 2 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/uchen_poor_quality_examples/uchen_poor quality.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/uchen_poor_quality_examples/uchen_poor quality(1).pdf\"  # 4 pages\n",
    "\n",
    "# --- UMEH HIGH QUALITY (6 files, 18 pages total) ---\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_high_quality_examples/umeh_druma_high quality.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_high_quality_examples/umeh_drutsa_high quality.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_high_quality_examples/umeh_dhernangdri_high quality(1).pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_high_quality_examples/umeh_dhernangdri_high quality.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_high_quality_examples/umeh_dhernangdri_high quality(2).pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_high_quality_examples/umeh_tsugma khyug_high quality.pdf\"  # 3 pages\n",
    "\n",
    "# --- UMEH MEDIUM QUALITY (5 files, 25 pages total) ---\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_medium_quality_examples/umeh_druchen_medium quality.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_medium_quality_examples/umeh_druchen_medium quality(1).pdf\"  # 4 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_medium_quality_examples/umeh_dhernangdri_medium quality.pdf\"  # 12 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_medium_quality_examples/umeh_tsugmakhyug_medium quality.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_medium_quality_examples/umeh_druchen_medium quality(2).pdf\"  # 3 pages\n",
    "\n",
    "# --- UMEH POOR QUALITY (4 files, 12 pages total) ---\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_poor_quality_examples/umeh_dhernangdri_poor quality(2).pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_poor_quality_examples/umeh_drutsa_poor quality.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_poor_quality_examples/umeh_khyugyig_poor quality.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/umeh_poor_quality_examples/umeh_petsug_poor quality.pdf\"  # 3 pages\n",
    "\n",
    "# --- PECHAS WITH MORE TEXT (3 files, 9 pages total) ---\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/Pechas with more text/pechas with more text 1.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/Pechas with more text/pechas with more text 2.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/Pechas with more text/pechas with more text 3.pdf\"  # 3 pages\n",
    "\n",
    "# --- PECHAS WITH LITTLE TEXT (3 files, 9 pages total) ---\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/Pechas with little text/pechas with little text 1.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/Pechas with little text/pechas with little text 2.pdf\"  # 3 pages\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/Pechas with little text/pechas with little text 3.pdf\"  # 3 pages\n",
    "\n",
    "# --- STANDALONE FILES (2 files, 14 pages total) ---\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/sangs rgyas sman bla dngos.pdf\"  # 2 pages - QUICKEST TEST\n",
    "# TARGET = BASE_DIR / \"input_files/tibetan_texts/sangs_rgyas_sman_gyi.pdf\"  # 12 pages\n",
    "\n",
    "# ============================================================================\n",
    "# MODELS - Choose based on what you're processing\n",
    "# ============================================================================\n",
    "\n",
    "MODELS_TO_TEST = [\"Woodblock\", \"Woodblock-Stacks\", \"Modern\"]  # For Uchen\n",
    "# MODELS_TO_TEST = [\"Ume_Druma\", \"Ume_Petsuk\", \"Modern\"]  # For Umeh\n",
    "\n",
    "# ============================================================================\n",
    "# Validation\n",
    "# ============================================================================\n",
    "if not TARGET.exists():\n",
    "    raise FileNotFoundError(f\"❌ File not found: {TARGET}\")\n",
    "\n",
    "# Setup output paths\n",
    "OUTPUT_DIR = BASE_DIR / \"grid_search_results\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "TEMP_DIR = OUTPUT_DIR / \"temp_images\"\n",
    "TEMP_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "CHECKPOINT_DIR = OUTPUT_DIR / \"_checkpoints\"\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "CHECKPOINT_FILE = CHECKPOINT_DIR / \"progress.json\"\n",
    "\n",
    "print(f\"✅ Target: {TARGET.name}\")\n",
    "print(f\"   Models: {MODELS_TO_TEST}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e294dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "LOGGING SETUP\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "LOGS_DIR = OUTPUT_DIR / \"logs\"\n",
    "LOGS_DIR.mkdir(exist_ok=True)\n",
    "LOG_FILE = LOGS_DIR / \"grid_search.log\"\n",
    "\n",
    "file_handler = RotatingFileHandler(\n",
    "    LOG_FILE, maxBytes=10*1024*1024, backupCount=5\n",
    ")\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S'\n",
    "))\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "console_handler.setFormatter(logging.Formatter('%(message)s'))\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, handlers=[file_handler, console_handler])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"=\" * 70)\n",
    "logger.info(\"GRID SEARCH SESSION STARTED\")\n",
    "logger.info(\"=\" * 70)\n",
    "logger.info(f\"Target File: {TARGET}\")\n",
    "logger.info(f\"Models: {MODELS_TO_TEST}\")\n",
    "logger.info(f\"Log file: {LOG_FILE}\")\n",
    "logger.info(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3432f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRQualityScorer:\n",
    "    \"\"\"Score OCR text quality using PyBo tokenization. Higher = more valid Tibetan words.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        if not PYBO_AVAILABLE:\n",
    "            self.tokenizer = None\n",
    "            print(\"⚠️  Quality scoring disabled (PyBo not available)\")\n",
    "        else:\n",
    "            self.tokenizer = WordTokenizer()\n",
    "            print(\"✅ Quality scorer initialized with PyBo\")\n",
    "\n",
    "    def score_text(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Score OCR text. Returns quality_score (0-100), total/valid/invalid token counts.\"\"\"\n",
    "        if not self.tokenizer or not text.strip():\n",
    "            return {'quality_score': 0.0, 'total_tokens': 0, 'valid_tokens': 0, 'invalid_tokens': 0}\n",
    "\n",
    "        try:\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            total_tokens = 0\n",
    "            valid_tokens = 0\n",
    "\n",
    "            for token in tokens:\n",
    "                pos = getattr(token, 'pos', None)\n",
    "                if pos == '':  # Skip punctuation\n",
    "                    continue\n",
    "                total_tokens += 1\n",
    "                if pos and pos not in ['NON_WORD', 'non-word', 'NO_POS', 'OTHER', '', None, 'X']:\n",
    "                    valid_tokens += 1\n",
    "\n",
    "            quality_score = (valid_tokens / total_tokens * 100) if total_tokens > 0 else 0.0\n",
    "            return {\n",
    "                'quality_score': round(quality_score, 2),\n",
    "                'total_tokens': total_tokens,\n",
    "                'valid_tokens': valid_tokens,\n",
    "                'invalid_tokens': total_tokens - valid_tokens\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️  Quality scoring error: {e}\")\n",
    "            return {'quality_score': 0.0, 'total_tokens': 0, 'valid_tokens': 0, 'invalid_tokens': 0}\n",
    "\n",
    "quality_scorer = OCRQualityScorer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26189c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "PARAMETER GRID\n",
    "=============================================================================\n",
    "\n",
    "Strategy:\n",
    "  - Use FULL_PARAMS for the FIRST image of each new category (1,728 combos)\n",
    "  - Analyze results, then create a trimmed grid for that category\n",
    "  - Use the trimmed grid for remaining images in that category\n",
    "  \n",
    "To add a new trimmed grid after analyzing a category:\n",
    "  1. Copy the UCHEN_HIGH_PARAMS template\n",
    "  2. Rename to match your category\n",
    "  3. Fill in the winning values from your analysis\n",
    "  4. Uncomment the PARAM_VALUES line for it below\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class GridSearchParams:\n",
    "    \"\"\"Parameters for a single grid search run.\"\"\"\n",
    "    ocr_model_name: str\n",
    "    line_mode: str       # \"line\" or \"layout\"\n",
    "    class_threshold: float\n",
    "    k_factor: float\n",
    "    bbox_tolerance: float\n",
    "    merge_lines: bool\n",
    "    tps_threshold: float  # use_tps always True, threshold controls sensitivity\n",
    "\n",
    "    def to_filename(self) -> str:\n",
    "        merge_str = \"T\" if self.merge_lines else \"F\"\n",
    "        return (\n",
    "            f\"{self.ocr_model_name}_{self.line_mode}_\"\n",
    "            f\"k{self.k_factor}_bbox{self.bbox_tolerance}_\"\n",
    "            f\"merge-{merge_str}_tps{self.tps_threshold}_conf{self.class_threshold}\"\n",
    "        )\n",
    "\n",
    "# ============================================================================\n",
    "# FULL GRID - 1,728 combos per image (use for first image of each category)\n",
    "# ============================================================================\n",
    "FULL_PARAMS = {\n",
    "    \"line_mode\": [\"line\", \"layout\"],\n",
    "    \"class_threshold\": [0.7, 0.8, 0.9],\n",
    "    \"k_factor\": [2.0, 2.5, 3.0],\n",
    "    \"bbox_tolerance\": [2.5, 3.5, 4.0, 5.0],\n",
    "    \"merge_lines\": [True, False],\n",
    "    \"tps_threshold\": [0.1, 0.25, 0.5, 0.9],\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# TRIMMED GRIDS - based on Phase 1 results per category\n",
    "# After running full grid on first image, analyze and add trimmed params here\n",
    "# ============================================================================\n",
    "\n",
    "# Uchen High Quality: 12 combos per image (from 1,728)\n",
    "# Based on: uchen high quality pdf - page 1 results\n",
    "UCHEN_HIGH_PARAMS = {\n",
    "    \"line_mode\": [\"line\"],              # line beat layout by 5pts\n",
    "    \"class_threshold\": [0.7],           # no difference observed\n",
    "    \"k_factor\": [2.5],                  # no difference observed\n",
    "    \"bbox_tolerance\": [2.5, 3.5, 4.0, 5.0],  # showed meaningful spread, keep all\n",
    "    \"merge_lines\": [True],              # 10pt advantage over False\n",
    "    \"tps_threshold\": [0.5],             # no difference on clean pages\n",
    "}\n",
    "\n",
    "# Uchen Medium Quality: TBD after first run\n",
    "# UCHEN_MED_PARAMS = {\n",
    "#     \"line_mode\": [],\n",
    "#     \"class_threshold\": [],\n",
    "#     \"k_factor\": [],\n",
    "#     \"bbox_tolerance\": [],\n",
    "#     \"merge_lines\": [],\n",
    "#     \"tps_threshold\": [],\n",
    "# }\n",
    "\n",
    "# Uchen Poor Quality: TBD after first run\n",
    "# UCHEN_POOR_PARAMS = {\n",
    "#     \"line_mode\": [],\n",
    "#     \"class_threshold\": [],\n",
    "#     \"k_factor\": [],\n",
    "#     \"bbox_tolerance\": [],\n",
    "#     \"merge_lines\": [],\n",
    "#     \"tps_threshold\": [],\n",
    "# }\n",
    "\n",
    "# Umeh High Quality: TBD after first run\n",
    "# UMEH_HIGH_PARAMS = {\n",
    "#     \"line_mode\": [],\n",
    "#     \"class_threshold\": [],\n",
    "#     \"k_factor\": [],\n",
    "#     \"bbox_tolerance\": [],\n",
    "#     \"merge_lines\": [],\n",
    "#     \"tps_threshold\": [],\n",
    "# }\n",
    "\n",
    "# Umeh Medium Quality: TBD after first run\n",
    "# UMEH_MED_PARAMS = {\n",
    "#     \"line_mode\": [],\n",
    "#     \"class_threshold\": [],\n",
    "#     \"k_factor\": [],\n",
    "#     \"bbox_tolerance\": [],\n",
    "#     \"merge_lines\": [],\n",
    "#     \"tps_threshold\": [],\n",
    "# }\n",
    "\n",
    "# Umeh Poor Quality: TBD after first run\n",
    "# UMEH_POOR_PARAMS = {\n",
    "#     \"line_mode\": [],\n",
    "#     \"class_threshold\": [],\n",
    "#     \"k_factor\": [],\n",
    "#     \"bbox_tolerance\": [],\n",
    "#     \"merge_lines\": [],\n",
    "#     \"tps_threshold\": [],\n",
    "# }\n",
    "\n",
    "# ============================================================================\n",
    "# ACTIVE SELECTION - uncomment ONE line\n",
    "# ============================================================================\n",
    "PARAM_VALUES = FULL_PARAMS\n",
    "# PARAM_VALUES = UCHEN_HIGH_PARAMS\n",
    "# PARAM_VALUES = UCHEN_MED_PARAMS\n",
    "# PARAM_VALUES = UCHEN_POOR_PARAMS\n",
    "# PARAM_VALUES = UMEH_HIGH_PARAMS\n",
    "# PARAM_VALUES = UMEH_MED_PARAMS\n",
    "# PARAM_VALUES = UMEH_POOR_PARAMS\n",
    "\n",
    "\n",
    "def generate_param_combinations() -> List[GridSearchParams]:\n",
    "    \"\"\"Generate all parameter combinations.\"\"\"\n",
    "    combos = []\n",
    "    for model in MODELS_TO_TEST:\n",
    "        for lm in PARAM_VALUES[\"line_mode\"]:\n",
    "            for ct in PARAM_VALUES[\"class_threshold\"]:\n",
    "                for kf in PARAM_VALUES[\"k_factor\"]:\n",
    "                    for bt in PARAM_VALUES[\"bbox_tolerance\"]:\n",
    "                        for ml in PARAM_VALUES[\"merge_lines\"]:\n",
    "                            for tp in PARAM_VALUES[\"tps_threshold\"]:\n",
    "                                combos.append(GridSearchParams(\n",
    "                                    ocr_model_name=model, line_mode=lm,\n",
    "                                    class_threshold=ct, k_factor=kf,\n",
    "                                    bbox_tolerance=bt, merge_lines=ml,\n",
    "                                    tps_threshold=tp\n",
    "                                ))\n",
    "    return combos\n",
    "\n",
    "\n",
    "# Show counts\n",
    "total_combos = len(MODELS_TO_TEST)\n",
    "for vals in PARAM_VALUES.values():\n",
    "    total_combos *= len(vals)\n",
    "print(f\"Parameter combinations per image: {total_combos}\")\n",
    "print(f\"Models: {MODELS_TO_TEST}\")\n",
    "for name, vals in PARAM_VALUES.items():\n",
    "    print(f\"  {name}: {vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "CORE ENGINE - OCR runner, checkpoint, results saving\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "class CheckpointManager:\n",
    "    \"\"\"Saves/loads progress for resumable grid search.\"\"\"\n",
    "\n",
    "    def __init__(self, checkpoint_file: Path):\n",
    "        self.checkpoint_file = checkpoint_file\n",
    "        self.completed = self._load()\n",
    "\n",
    "    def _load(self) -> set:\n",
    "        if self.checkpoint_file.exists():\n",
    "            try:\n",
    "                with open(self.checkpoint_file, 'r') as f:\n",
    "                    return set(json.load(f).get(\"completed_images\", []))\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load checkpoint: {e}\")\n",
    "        return set()\n",
    "\n",
    "    def save(self):\n",
    "        data = {\"completed_images\": list(self.completed), \"last_updated\": datetime.now().isoformat()}\n",
    "        with open(self.checkpoint_file, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "    def mark_completed(self, image_path: str):\n",
    "        self.completed.add(image_path)\n",
    "        self.save()\n",
    "\n",
    "    def is_completed(self, image_path: str) -> bool:\n",
    "        return image_path in self.completed\n",
    "\n",
    "    def get_completed_count(self) -> int:\n",
    "        return len(self.completed)\n",
    "\n",
    "    def reset(self):\n",
    "        self.completed = set()\n",
    "        if self.checkpoint_file.exists():\n",
    "            self.checkpoint_file.unlink()\n",
    "\n",
    "\n",
    "class GracefulInterrupt:\n",
    "    \"\"\"Handle Ctrl+C gracefully, allowing current image to complete.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.interrupted = False\n",
    "        self._original_handler = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._original_handler = signal.signal(signal.SIGINT, self._handler)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        signal.signal(signal.SIGINT, self._original_handler)\n",
    "\n",
    "    def _handler(self, signum, frame):\n",
    "        print(\"\\\n",
    "\\\n",
    "⚠️  Interrupt received. Finishing current image then stopping...\")\n",
    "        print(\"   (Press Ctrl+C again to force quit)\\\n",
    "\")\n",
    "        self.interrupted = True\n",
    "        signal.signal(signal.SIGINT, self._original_handler)\n",
    "\n",
    "\n",
    "class GridSearchOCR:\n",
    "    \"\"\"Runs OCR with different parameter combinations.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.platform = get_platform()\n",
    "        self.ocr_models = {}\n",
    "        self.pipelines = {}\n",
    "\n",
    "        # Line detection configs\n",
    "        self.line_config = LineDetectionConfig(model_file=str(LINE_MODEL_PATH), patch_size=512)\n",
    "        self.layout_config = LayoutDetectionConfig(\n",
    "            model_file=str(LAYOUT_MODEL_PATH), patch_size=512,\n",
    "            classes=[\"background\", \"image\", \"line\", \"caption\", \"margin\"]\n",
    "        )\n",
    "\n",
    "        # Load OCR models\n",
    "        print(\"\\\n",
    "Loading OCR models...\")\n",
    "        models = import_local_models(str(OCR_MODELS_DIR))\n",
    "        for model in models:\n",
    "            self.ocr_models[model.name] = model\n",
    "            print(f\"  ✅ Loaded: {model.name}\")\n",
    "\n",
    "    def run_ocr(self, image_path: Path, params: GridSearchParams) -> Tuple[bool, int, str, str, Dict]:\n",
    "        \"\"\"Run OCR on a single image. Returns (success, num_lines, text, error, quality_metrics).\"\"\"\n",
    "        try:\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                return False, 0, \"\", f\"Failed to load image: {image_path}\", {}\n",
    "\n",
    "            # Get or create pipeline\n",
    "            cache_key = f\"{params.ocr_model_name}_{params.line_mode}\"\n",
    "            if cache_key not in self.pipelines:\n",
    "                ocr_model = self.ocr_models.get(params.ocr_model_name)\n",
    "                if not ocr_model:\n",
    "                    return False, 0, \"\", f\"OCR model not found: {params.ocr_model_name}\", {}\n",
    "                det_config = self.line_config if params.line_mode == \"line\" else self.layout_config\n",
    "                self.pipelines[cache_key] = OCRPipeline(\n",
    "                    platform=self.platform, ocr_config=ocr_model.config, line_config=det_config\n",
    "                )\n",
    "\n",
    "            pipeline = self.pipelines[cache_key]\n",
    "\n",
    "            status, result = pipeline.run_ocr(\n",
    "                image=image,\n",
    "                k_factor=params.k_factor,\n",
    "                bbox_tolerance=params.bbox_tolerance,\n",
    "                merge_lines=params.merge_lines,\n",
    "                use_tps=True,\n",
    "                tps_threshold=params.tps_threshold,\n",
    "                target_encoding=Encoding.Unicode\n",
    "            )\n",
    "\n",
    "            if status.name == \"SUCCESS\":\n",
    "                rot_mask, sorted_lines, ocr_lines, page_angle = result\n",
    "                full_text = \"\\\n",
    "\".join(line.text for line in ocr_lines)\n",
    "                quality = quality_scorer.score_text(full_text)\n",
    "                return True, len(ocr_lines), full_text, \"\", quality\n",
    "            else:\n",
    "                return False, 0, \"\", str(result), {}\n",
    "\n",
    "        except Exception as e:\n",
    "            return False, 0, \"\", str(e), {}\n",
    "\n",
    "\n",
    "def get_test_images() -> Dict[str, List[Path]]:\n",
    "    \"\"\"Extract images from TARGET PDF. Returns {pdf_stem: [image_paths]}.\"\"\"\n",
    "    pdf_output_dir = TEMP_DIR / TARGET.stem\n",
    "    pdf_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    existing = sorted(pdf_output_dir.glob(\"*.jpg\"))\n",
    "    if existing:\n",
    "        print(f\"  Using {len(existing)} existing images from {TARGET.name}\")\n",
    "    else:\n",
    "        print(f\"  Extracting images from {TARGET.name}...\")\n",
    "        extracted, total = extract_images_from_pdf(str(TARGET), str(pdf_output_dir))\n",
    "        print(f\"  Extracted {len(extracted)} images from {total} pages\")\n",
    "        existing = sorted(Path(p) for p in extracted)\n",
    "\n",
    "    return {TARGET.stem: existing}\n",
    "\n",
    "\n",
    "def save_result(output_dir, file_name, image_name, params, success,\n",
    "                num_lines, ocr_text, error_message, processing_time, quality_metrics):\n",
    "    \"\"\"Save a single OCR result to a text file.\"\"\"\n",
    "    result_dir = output_dir / file_name / image_name\n",
    "    result_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    filepath = result_dir / (params.to_filename() + \".txt\")\n",
    "\n",
    "    lines = [\n",
    "        \"=\" * 70, \"OCR RESULT\", \"=\" * 70, \"\",\n",
    "        f\"File: {file_name}\", f\"Image: {image_name}\", \"\",\n",
    "        \"PARAMETERS:\",\n",
    "        f\"  OCR Model: {params.ocr_model_name}\",\n",
    "        f\"  Line Mode: {params.line_mode}\",\n",
    "        f\"  Class Threshold: {params.class_threshold}\",\n",
    "        f\"  K-Factor: {params.k_factor}\",\n",
    "        f\"  BBox Tolerance: {params.bbox_tolerance}\",\n",
    "        f\"  Merge Lines: {params.merge_lines}\",\n",
    "        f\"  TPS Threshold: {params.tps_threshold}\", \"\",\n",
    "        \"RESULTS:\",\n",
    "        f\"  Success: {success}\",\n",
    "        f\"  Lines Detected: {num_lines}\",\n",
    "        f\"  Processing Time: {processing_time:.2f}s\",\n",
    "    ]\n",
    "\n",
    "    if quality_metrics:\n",
    "        lines += [\n",
    "            \"\", \"QUALITY METRICS:\",\n",
    "            f\"  Quality Score: {quality_metrics.get('quality_score', 0):.2f}/100\",\n",
    "            f\"  Total Tokens: {quality_metrics.get('total_tokens', 0)}\",\n",
    "            f\"  Valid Words: {quality_metrics.get('valid_tokens', 0)}\",\n",
    "            f\"  Invalid Words: {quality_metrics.get('invalid_tokens', 0)}\",\n",
    "        ]\n",
    "\n",
    "    if error_message:\n",
    "        lines.append(f\"  Error: {error_message}\")\n",
    "\n",
    "    lines += [\"\", \"=\" * 70, \"OCR TEXT\", \"=\" * 70, \"\",\n",
    "              ocr_text if ocr_text else \"[No text extracted]\"]\n",
    "\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\\n",
    "\".join(lines))\n",
    "\n",
    "\n",
    "def save_summary_csv(output_dir: Path, all_results: List[Dict]):\n",
    "    \"\"\"Save summary CSV of all results.\"\"\"\n",
    "    csv_path = output_dir / \"summary.csv\"\n",
    "    if not all_results:\n",
    "        print(\"No results to save\")\n",
    "        return\n",
    "    fieldnames = list(all_results[0].keys())\n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_results)\n",
    "    print(f\"\\\n",
    "?? Summary saved: {csv_path}\")\n",
    "\n",
    "\n",
    "def run_grid_search(max_images: int = None, resume: bool = True):\n",
    "    \"\"\"\n",
    "    Run the full grid search.\n",
    "\n",
    "    Args:\n",
    "        max_images: Limit number of images (for testing)\n",
    "        resume: Resume from checkpoint (default True)\n",
    "    \"\"\"\n",
    "    checkpoint = CheckpointManager(CHECKPOINT_FILE)\n",
    "    ocr = GridSearchOCR()\n",
    "    all_results = []\n",
    "\n",
    "    if resume and checkpoint.get_completed_count() > 0:\n",
    "        print(f\"\\\n",
    "?? Resuming: {checkpoint.get_completed_count()} images already done\")\n",
    "    elif not resume:\n",
    "        checkpoint.reset()\n",
    "        print(\"\\\n",
    "?? Starting fresh\")\n",
    "\n",
    "    # Get images\n",
    "    print(\"\\\n",
    "\" + \"=\" * 70)\n",
    "    print(\"LOADING IMAGES\")\n",
    "    print(\"=\" * 70)\n",
    "    images_by_file = get_test_images()\n",
    "\n",
    "    total_images = sum(len(imgs) for imgs in images_by_file.values())\n",
    "    param_combos = generate_param_combinations()\n",
    "\n",
    "    print(f\"\\\n",
    "\" + \"=\" * 70)\n",
    "    print(\"GRID SEARCH\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Images: {total_images}\")\n",
    "    print(f\"Combinations per image: {len(param_combos)}\")\n",
    "    print(f\"Total iterations: {total_images * len(param_combos)}\")\n",
    "    print(f\"Output: {OUTPUT_DIR}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    with GracefulInterrupt() as interrupt:\n",
    "        images_processed = 0\n",
    "        images_skipped = 0\n",
    "\n",
    "        for file_name, image_paths in sorted(images_by_file.items()):\n",
    "            if interrupt.interrupted:\n",
    "                break\n",
    "\n",
    "            if max_images:\n",
    "                image_paths = image_paths[:max_images]\n",
    "\n",
    "            print(f\"\\\n",
    "?? {file_name} ({len(image_paths)} images)\")\n",
    "\n",
    "            for image_path in image_paths:\n",
    "                if interrupt.interrupted:\n",
    "                    break\n",
    "\n",
    "                image_key = str(image_path)\n",
    "                image_name = image_path.stem\n",
    "\n",
    "                if checkpoint.is_completed(image_key):\n",
    "                    images_skipped += 1\n",
    "                    continue\n",
    "\n",
    "                print(f\"\\\n",
    "   ??️  {image_name}\")\n",
    "\n",
    "                pbar = tqdm(param_combos, desc=\"      Params\", leave=False)\n",
    "                for params in pbar:\n",
    "                    t0 = time.time()\n",
    "                    success, num_lines, ocr_text, error, quality = ocr.run_ocr(image_path, params)\n",
    "                    elapsed = time.time() - t0\n",
    "\n",
    "                    save_result(OUTPUT_DIR, file_name, image_name, params,\n",
    "                                success, num_lines, ocr_text, error, elapsed, quality)\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"file_name\": file_name,\n",
    "                        \"image_name\": image_name,\n",
    "                        \"ocr_model_name\": params.ocr_model_name,\n",
    "                        \"line_mode\": params.line_mode,\n",
    "                        \"class_threshold\": params.class_threshold,\n",
    "                        \"k_factor\": params.k_factor,\n",
    "                        \"bbox_tolerance\": params.bbox_tolerance,\n",
    "                        \"merge_lines\": params.merge_lines,\n",
    "                        \"tps_threshold\": params.tps_threshold,\n",
    "                        \"success\": success,\n",
    "                        \"num_lines_detected\": num_lines,\n",
    "                        \"processing_time\": elapsed,\n",
    "                        \"quality_score\": quality.get('quality_score', 0.0),\n",
    "                        \"total_tokens\": quality.get('total_tokens', 0),\n",
    "                        \"valid_tokens\": quality.get('valid_tokens', 0),\n",
    "                        \"invalid_tokens\": quality.get('invalid_tokens', 0),\n",
    "                        \"error\": error[:100] if error else \"\"\n",
    "                    })\n",
    "                pbar.close()\n",
    "\n",
    "                checkpoint.mark_completed(image_key)\n",
    "                images_processed += 1\n",
    "                print(f\"      ✅ Done ({images_processed} processed, {images_skipped} skipped)\")\n",
    "\n",
    "        save_summary_csv(OUTPUT_DIR, all_results)\n",
    "\n",
    "    print(\"\\\n",
    "\" + \"=\" * 70)\n",
    "    if interrupt.interrupted:\n",
    "        print(\"⚠️  INTERRUPTED - Progress saved, run again to resume\")\n",
    "    else:\n",
    "        print(\"✅ GRID SEARCH COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Processed: {images_processed}  Skipped: {images_skipped}\")\n",
    "    print(f\"Results: {OUTPUT_DIR}\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def analyze_results():\n",
    "    \"\"\"Load and analyze results from summary.csv.\"\"\"\n",
    "    csv_path = OUTPUT_DIR / \"summary.csv\"\n",
    "    if not csv_path.exists():\n",
    "        print(\"❌ No summary.csv found. Run grid search first.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        import pandas as pd\n",
    "    except ImportError:\n",
    "        print(\"❌ pandas required: pip install pandas\")\n",
    "        return None\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    print(\"\\\n",
    "\" + \"=\" * 70)\n",
    "    print(\"ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\\n",
    "Total results: {len(df)}\")\n",
    "\n",
    "    successful = df[df['success'] == True]\n",
    "\n",
    "    print(\"\\\n",
    "?? Success Rate by Model:\")\n",
    "    print(df.groupby('ocr_model_name')['success'].mean().sort_values(ascending=False))\n",
    "\n",
    "    if len(successful) > 0:\n",
    "        print(\"\\\n",
    "✨ Avg Quality Score by Model:\")\n",
    "        print(successful.groupby('ocr_model_name')['quality_score'].mean().sort_values(ascending=False))\n",
    "\n",
    "        print(\"\\\n",
    "✨ Avg Quality Score by Line Mode:\")\n",
    "        print(successful.groupby('line_mode')['quality_score'].mean())\n",
    "\n",
    "        print(\"\\\n",
    "✨ Avg Quality Score by K-Factor:\")\n",
    "        print(successful.groupby('k_factor')['quality_score'].mean())\n",
    "\n",
    "        print(\"\\\n",
    "?? TOP 10 (by quality score):\")\n",
    "        top10 = successful.nlargest(10, 'quality_score')[\n",
    "            ['file_name', 'image_name', 'ocr_model_name', 'line_mode',\n",
    "             'k_factor', 'bbox_tolerance', 'quality_score', 'num_lines_detected']\n",
    "        ]\n",
    "        print(top10.to_string(index=False))\n",
    "\n",
    "        print(\"\\\n",
    "?? Quality Distribution:\")\n",
    "        print(f\"  >90 (Excellent): {len(df[df['quality_score'] > 90])}\")\n",
    "        print(f\"  70-90 (Good):    {len(df[(df['quality_score'] >= 70) & (df['quality_score'] <= 90)])}\")\n",
    "        print(f\"  50-70 (Fair):    {len(df[(df['quality_score'] >= 50) & (df['quality_score'] < 70)])}\")\n",
    "        print(f\"  <50 (Poor):      {len(df[df['quality_score'] < 50])}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15eff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quick test: 1 image, all parameter combos.\n",
    "Verify everything works before the full run.\n",
    "\"\"\"\n",
    "checkpoint = CheckpointManager(CHECKPOINT_FILE)\n",
    "checkpoint.reset()\n",
    "quick_results = run_grid_search(max_images=1, resume=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f045bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full grid search on all images from TARGET.\n",
    "Resumes from checkpoint if interrupted.\n",
    "Press kernel interrupt to stop gracefully.\n",
    "\"\"\"\n",
    "results = run_grid_search()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c286b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "View summary statistics and top parameter combos.\n",
    "\"\"\"\n",
    "df = analyze_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Clear checkpoint to start fresh on next run.\n",
    "\"\"\"\n",
    "# checkpoint = CheckpointManager(CHECKPOINT_FILE)\n",
    "# checkpoint.reset()\n",
    "# print(\"✅ Checkpoint cleared\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
