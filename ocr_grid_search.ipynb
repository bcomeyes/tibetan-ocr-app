{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e26a2f",
   "metadata": {},
   "source": [
    "# Tibetan OCR Grid Search with Quality Scoring\n",
    "\n",
    "This notebook systematically tests OCR parameter combinations across different\n",
    "Tibetan script types (Uchen/Umeh) and quality levels to find optimal settings.\n",
    "\n",
    "**NEW: Automated OCR Quality Scoring with PyBo**\n",
    "- Each OCR output is automatically scored using PyBo tokenization\n",
    "- Score represents % of valid Tibetan words (0-100)\n",
    "- Results are ranked by quality score\n",
    "- Top performers can be reviewed first, skipping garbage outputs\n",
    "\n",
    "## Design Decisions\n",
    "\n",
    "**Model-to-Script Matching:**\n",
    "- Uchen samples â†’ Woodblock, Woodblock-Stacks, Modern\n",
    "- Umeh samples â†’ Ume_Druma, Ume_Petsuk, Modern\n",
    "\n",
    "**Parameters Tested:**\n",
    "- ocr_model_name: Which OCR model (matched to script type)\n",
    "- line_mode: \"line\" or \"layout\" detection\n",
    "- k_factor: Line extraction expansion [2.0, 2.5, 3.0]\n",
    "- bbox_tolerance: Bounding box merge tolerance [2.5, 3.5, 4.0, 5.0]\n",
    "- merge_lines: Whether to merge line chunks [True, False]\n",
    "- tps_threshold: Dewarping sensitivity [0.1, 0.25, 0.5, 0.9]\n",
    "- class_threshold: Line detection confidence [0.7, 0.8, 0.9]\n",
    "\n",
    "## OCR Quality Scoring\n",
    "\n",
    "After each OCR run, PyBo tokenizes the output text and calculates:\n",
    "- **Quality Score**: Percentage of tokens that are valid Tibetan words (0-100)\n",
    "- **High scores (>90)**: Likely excellent OCR output\n",
    "- **Medium scores (50-90)**: Mixed quality\n",
    "- **Low scores (<50)**: Likely garbage output\n",
    "\n",
    "This allows automatic filtering: instead of manually reviewing 1,728 outputs,\n",
    "you can focus on the top 50-100 highest-scoring results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e14314",
   "metadata": {
    "title": "Imports and Path Setup"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import json\n",
    "import signal\n",
    "import itertools\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "# PyBo for OCR quality scoring\n",
    "try:\n",
    "    from pybo import WordTokenizer\n",
    "    PYBO_AVAILABLE = True\n",
    "    print(\"âœ… PyBo loaded for OCR quality scoring\")\n",
    "except ImportError:\n",
    "    PYBO_AVAILABLE = False\n",
    "    print(\"âš ï¸  PyBo not available - quality scoring disabled\")\n",
    "    print(\"   Install with: pip install git+https://github.com/OpenPecha/pybo.git\")\n",
    "\n",
    "# Add the project root to path\n",
    "PROJECT_ROOT = Path(__file__).parent if \"__file__\" in dir() else Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Now import BDRC modules\n",
    "from BDRC.Data import (\n",
    "    Encoding, LineMode, TPSMode, Platform,\n",
    "    LineDetectionConfig, LayoutDetectionConfig, OCRModelConfig\n",
    ")\n",
    "from BDRC.Inference import OCRPipeline\n",
    "from BDRC.Utils import import_local_models, get_platform\n",
    "from BDRC.utils.pdf_extract import extract_images_from_pdf\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Platform: {get_platform()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55661d5",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Configuration - EDIT THESE PATHS"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "CONFIGURATION - Edit these paths to match your local setup\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "# Base directory for the tibetan-ocr-app\n",
    "BASE_DIR = Path.home() / \"Documents\" / \"tibetan-ocr-app\"\n",
    "\n",
    "# Model paths\n",
    "OCR_MODELS_DIR = BASE_DIR / \"OCRModels\"\n",
    "LINE_MODEL_PATH = BASE_DIR / \"Models\" / \"Lines\" / \"PhotiLines.onnx\"\n",
    "LAYOUT_MODEL_PATH = BASE_DIR / \"Models\" / \"Layout\" / \"photi.onnx\"\n",
    "\n",
    "# Test samples directory\n",
    "TEST_SAMPLES_DIR = BASE_DIR / \"input_files\"\n",
    "\n",
    "# Output directory for results\n",
    "OUTPUT_DIR = BASE_DIR / \"grid_search_results\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Temp directory for extracted PDF images\n",
    "TEMP_DIR = OUTPUT_DIR / \"temp_images\"\n",
    "TEMP_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Checkpoint directory\n",
    "CHECKPOINT_DIR = OUTPUT_DIR / \"_checkpoints\"\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "CHECKPOINT_FILE = CHECKPOINT_DIR / \"progress.json\"\n",
    "\n",
    "print(f\"OCR Models: {OCR_MODELS_DIR}\")\n",
    "print(f\"Test Samples: {TEST_SAMPLES_DIR}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65ebee",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Initialize PyBo Quality Scorer"
   },
   "outputs": [],
   "source": [
    "class OCRQualityScorer:\n",
    "    \"\"\"\n",
    "    Score OCR text quality using PyBo tokenization.\n",
    "    \n",
    "    Higher scores = more valid Tibetan words recognized by THL lexicon.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        if not PYBO_AVAILABLE:\n",
    "            self.tokenizer = None\n",
    "            print(\"âš ï¸  Quality scoring disabled (PyBo not available)\")\n",
    "        else:\n",
    "            self.tokenizer = WordTokenizer()\n",
    "            print(\"âœ… Quality scorer initialized with PyBo\")\n",
    "    \n",
    "    def score_text(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Score OCR text quality.\n",
    "        \n",
    "        Returns:\n",
    "            dict with keys:\n",
    "                - quality_score: 0-100, percentage of valid words\n",
    "                - total_tokens: number of word tokens\n",
    "                - valid_tokens: number recognized in lexicon\n",
    "                - invalid_tokens: number not recognized\n",
    "        \"\"\"\n",
    "        if not self.tokenizer or not text.strip():\n",
    "            return {\n",
    "                'quality_score': 0.0,\n",
    "                'total_tokens': 0,\n",
    "                'valid_tokens': 0,\n",
    "                'invalid_tokens': 0\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            \n",
    "            total_tokens = 0\n",
    "            valid_tokens = 0\n",
    "            invalid_tokens = 0\n",
    "            \n",
    "            for token in tokens:\n",
    "                # Get attributes safely\n",
    "                pos = getattr(token, 'pos', None)\n",
    "                \n",
    "                # Skip punctuation (empty POS)\n",
    "                if pos == '':\n",
    "                    continue\n",
    "                \n",
    "                total_tokens += 1\n",
    "                \n",
    "                # Valid if has real POS tag (not NON_WORD, NO_POS, OTHER, etc.)\n",
    "                if pos and pos not in ['NON_WORD', 'non-word', 'NO_POS', 'OTHER', '', None, 'X']:\n",
    "                    valid_tokens += 1\n",
    "                else:\n",
    "                    invalid_tokens += 1\n",
    "            \n",
    "            quality_score = (valid_tokens / total_tokens * 100) if total_tokens > 0 else 0.0\n",
    "            \n",
    "            return {\n",
    "                'quality_score': round(quality_score, 2),\n",
    "                'total_tokens': total_tokens,\n",
    "                'valid_tokens': valid_tokens,\n",
    "                'invalid_tokens': invalid_tokens\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸  Quality scoring error: {e}\")\n",
    "            return {\n",
    "                'quality_score': 0.0,\n",
    "                'total_tokens': 0,\n",
    "                'valid_tokens': 0,\n",
    "                'invalid_tokens': 0\n",
    "            }\n",
    "\n",
    "# Initialize global scorer\n",
    "quality_scorer = OCRQualityScorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14446f",
   "metadata": {
    "title": "Verify paths exist"
   },
   "outputs": [],
   "source": [
    "def verify_setup():\n",
    "    \"\"\"Verify all required paths and models exist.\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    if not OCR_MODELS_DIR.exists():\n",
    "        errors.append(f\"OCR Models directory not found: {OCR_MODELS_DIR}\")\n",
    "    \n",
    "    if not LINE_MODEL_PATH.exists():\n",
    "        errors.append(f\"Line detection model not found: {LINE_MODEL_PATH}\")\n",
    "    \n",
    "    if not LAYOUT_MODEL_PATH.exists():\n",
    "        errors.append(f\"Layout detection model not found: {LAYOUT_MODEL_PATH}\")\n",
    "    \n",
    "    if not TEST_SAMPLES_DIR.exists():\n",
    "        errors.append(f\"Test samples directory not found: {TEST_SAMPLES_DIR}\")\n",
    "    \n",
    "    if errors:\n",
    "        print(\"âŒ Setup errors:\")\n",
    "        for e in errors:\n",
    "            print(f\"   - {e}\")\n",
    "        return False\n",
    "    \n",
    "    # List available OCR models\n",
    "    ocr_models = list(OCR_MODELS_DIR.iterdir())\n",
    "    print(f\"âœ… Found {len(ocr_models)} OCR models:\")\n",
    "    for m in ocr_models:\n",
    "        if m.is_dir():\n",
    "            print(f\"   - {m.name}\")\n",
    "    \n",
    "    # List test sample files (JSON or PDF)\n",
    "    test_files = list(TEST_SAMPLES_DIR.glob(\"*.json\")) + list(TEST_SAMPLES_DIR.glob(\"*.pdf\"))\n",
    "    print(f\"\\nâœ… Found {len(test_files)} test files:\")\n",
    "    for f in test_files[:10]:  # Show first 10\n",
    "        print(f\"   - {f.name}\")\n",
    "    if len(test_files) > 10:\n",
    "        print(f\"   ... and {len(test_files) - 10} more\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "verify_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4304699",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Define Parameter Grid"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "PARAMETER GRID DEFINITION\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class GridSearchParams:\n",
    "    \"\"\"Parameters for a single grid search run.\"\"\"\n",
    "    # OCR Model\n",
    "    ocr_model_name: str\n",
    "    \n",
    "    # Line detection\n",
    "    line_mode: str  # \"line\" or \"layout\"\n",
    "    class_threshold: float  # Confidence threshold for detection\n",
    "    \n",
    "    # Line processing\n",
    "    k_factor: float  # Line extraction expansion\n",
    "    bbox_tolerance: float  # BBox merge tolerance\n",
    "    merge_lines: bool  # Merge line chunks\n",
    "    \n",
    "    # Dewarping (use_tps always True, threshold controls sensitivity)\n",
    "    tps_threshold: float  # 0.9 = effectively off, 0.1 = aggressive\n",
    "    \n",
    "    def to_filename(self) -> str:\n",
    "        \"\"\"Generate a descriptive filename from parameters.\"\"\"\n",
    "        merge_str = \"T\" if self.merge_lines else \"F\"\n",
    "        return (\n",
    "            f\"{self.ocr_model_name}_{self.line_mode}_\"\n",
    "            f\"k{self.k_factor}_bbox{self.bbox_tolerance}_\"\n",
    "            f\"merge-{merge_str}_tps{self.tps_threshold}_conf{self.class_threshold}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Models for testing (will auto-detect from input files)\n",
    "# Assuming all Tengyur files are Uchen for now\n",
    "MODELS_TO_TEST = [\"Woodblock\", \"Woodblock-Stacks\", \"Modern\"]\n",
    "\n",
    "# Parameter values to test\n",
    "PARAM_VALUES = {\n",
    "    \"line_mode\": [\"line\", \"layout\"],\n",
    "    \"class_threshold\": [0.7, 0.8, 0.9],\n",
    "    \"k_factor\": [2.0, 2.5, 3.0],\n",
    "    \"bbox_tolerance\": [2.5, 3.5, 4.0, 5.0],\n",
    "    \"merge_lines\": [True, False],\n",
    "    \"tps_threshold\": [0.1, 0.25, 0.5, 0.9],\n",
    "}\n",
    "\n",
    "\n",
    "def generate_param_combinations() -> List[GridSearchParams]:\n",
    "    \"\"\"Generate all parameter combinations.\"\"\"\n",
    "    \n",
    "    combinations = []\n",
    "    \n",
    "    for model in MODELS_TO_TEST:\n",
    "        for line_mode in PARAM_VALUES[\"line_mode\"]:\n",
    "            for class_threshold in PARAM_VALUES[\"class_threshold\"]:\n",
    "                for k_factor in PARAM_VALUES[\"k_factor\"]:\n",
    "                    for bbox_tolerance in PARAM_VALUES[\"bbox_tolerance\"]:\n",
    "                        for merge_lines in PARAM_VALUES[\"merge_lines\"]:\n",
    "                            for tps_threshold in PARAM_VALUES[\"tps_threshold\"]:\n",
    "                                combinations.append(GridSearchParams(\n",
    "                                    ocr_model_name=model,\n",
    "                                    line_mode=line_mode,\n",
    "                                    class_threshold=class_threshold,\n",
    "                                    k_factor=k_factor,\n",
    "                                    bbox_tolerance=bbox_tolerance,\n",
    "                                    merge_lines=merge_lines,\n",
    "                                    tps_threshold=tps_threshold,\n",
    "                                ))\n",
    "    \n",
    "    return combinations\n",
    "\n",
    "\n",
    "def calculate_combinations_count() -> int:\n",
    "    \"\"\"Calculate total combinations.\"\"\"\n",
    "    total = len(MODELS_TO_TEST)\n",
    "    for values in PARAM_VALUES.values():\n",
    "        total *= len(values)\n",
    "    return total\n",
    "\n",
    "\n",
    "# Show combination counts\n",
    "total_combos = calculate_combinations_count()\n",
    "print(f\"\\nParameter combinations per image: {total_combos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d73a74",
   "metadata": {
    "title": "Checkpoint Management"
   },
   "outputs": [],
   "source": [
    "class CheckpointManager:\n",
    "    \"\"\"Manages saving and loading progress for resumable grid search.\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_file: Path):\n",
    "        self.checkpoint_file = checkpoint_file\n",
    "        self.completed = self._load()\n",
    "    \n",
    "    def _load(self) -> set:\n",
    "        \"\"\"Load completed image paths from checkpoint file.\"\"\"\n",
    "        if self.checkpoint_file.exists():\n",
    "            try:\n",
    "                with open(self.checkpoint_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    return set(data.get(\"completed_images\", []))\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load checkpoint: {e}\")\n",
    "                return set()\n",
    "        return set()\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Save current progress to checkpoint file.\"\"\"\n",
    "        data = {\n",
    "            \"completed_images\": list(self.completed),\n",
    "            \"last_updated\": datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self.checkpoint_file, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "    \n",
    "    def mark_completed(self, image_path: str):\n",
    "        \"\"\"Mark an image as fully processed (all param combinations done).\"\"\"\n",
    "        self.completed.add(image_path)\n",
    "        self.save()\n",
    "    \n",
    "    def is_completed(self, image_path: str) -> bool:\n",
    "        \"\"\"Check if an image has already been fully processed.\"\"\"\n",
    "        return image_path in self.completed\n",
    "    \n",
    "    def get_completed_count(self) -> int:\n",
    "        \"\"\"Get number of completed images.\"\"\"\n",
    "        return len(self.completed)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Clear all checkpoint data.\"\"\"\n",
    "        self.completed = set()\n",
    "        if self.checkpoint_file.exists():\n",
    "            self.checkpoint_file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c21b55",
   "metadata": {
    "title": "Graceful Interruption Handler"
   },
   "outputs": [],
   "source": [
    "class GracefulInterrupt:\n",
    "    \"\"\"Handle Ctrl+C gracefully, allowing current image to complete.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.interrupted = False\n",
    "        self._original_handler = None\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self._original_handler = signal.signal(signal.SIGINT, self._handler)\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        signal.signal(signal.SIGINT, self._original_handler)\n",
    "    \n",
    "    def _handler(self, signum, frame):\n",
    "        print(\"\\n\\nâš ï¸  Interrupt received. Finishing current image then stopping...\")\n",
    "        print(\"   (Press Ctrl+C again to force quit)\\n\")\n",
    "        self.interrupted = True\n",
    "        # Restore original handler so second Ctrl+C forces quit\n",
    "        signal.signal(signal.SIGINT, self._original_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248df67f",
   "metadata": {
    "title": "Helper Functions"
   },
   "outputs": [],
   "source": [
    "def load_images_from_json(json_path: Path) -> List[np.ndarray]:\n",
    "    \"\"\"Load images from Tengyur JSON file.\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    images = []\n",
    "    for folio in data:\n",
    "        # Assuming JSON structure has image data - adapt as needed\n",
    "        # For now, just return empty list as placeholder\n",
    "        pass\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "def get_all_test_images() -> Dict[str, List[Path]]:\n",
    "    \"\"\"Get all test images from JSON files.\"\"\"\n",
    "    images_by_file = {}\n",
    "    \n",
    "    # For JSON files, we'll need to extract images first\n",
    "    # For now, just look for existing image files\n",
    "    for json_path in sorted(TEST_SAMPLES_DIR.glob(\"*.json\")):\n",
    "        # For Tengyur JSONs, we'd need to convert to images\n",
    "        # This is a placeholder - implement based on your JSON structure\n",
    "        print(f\"Found JSON: {json_path.name}\")\n",
    "        images_by_file[json_path.stem] = []\n",
    "    \n",
    "    # Also check for any existing image files\n",
    "    for img_path in sorted(TEST_SAMPLES_DIR.glob(\"*.jpg\")) + sorted(TEST_SAMPLES_DIR.glob(\"*.png\")):\n",
    "        file_key = img_path.stem\n",
    "        if file_key not in images_by_file:\n",
    "            images_by_file[file_key] = []\n",
    "        images_by_file[file_key].append(img_path)\n",
    "    \n",
    "    return images_by_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a4de8",
   "metadata": {
    "title": "OCR Pipeline Wrapper"
   },
   "outputs": [],
   "source": [
    "class GridSearchOCR:\n",
    "    \"\"\"Wrapper for running OCR with different parameter combinations.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.platform = get_platform()\n",
    "        self.ocr_models = {}\n",
    "        self.pipelines = {}\n",
    "        \n",
    "        # Load line detection config\n",
    "        self.line_config = LineDetectionConfig(\n",
    "            model_file=str(LINE_MODEL_PATH),\n",
    "            patch_size=512\n",
    "        )\n",
    "        \n",
    "        # Load layout detection config\n",
    "        self.layout_config = LayoutDetectionConfig(\n",
    "            model_file=str(LAYOUT_MODEL_PATH),\n",
    "            patch_size=512,\n",
    "            classes=[\"background\", \"image\", \"line\", \"caption\", \"margin\"]\n",
    "        )\n",
    "        \n",
    "        # Load all OCR models\n",
    "        self._load_ocr_models()\n",
    "    \n",
    "    def _load_ocr_models(self):\n",
    "        \"\"\"Load all available OCR models.\"\"\"\n",
    "        print(\"\\nLoading OCR models...\")\n",
    "        \n",
    "        models = import_local_models(str(OCR_MODELS_DIR))\n",
    "        for model in models:\n",
    "            self.ocr_models[model.name] = model\n",
    "            print(f\"  âœ… Loaded: {model.name}\")\n",
    "    \n",
    "    def get_pipeline(self, params: GridSearchParams) -> OCRPipeline:\n",
    "        \"\"\"Get or create a pipeline for the given parameters.\"\"\"\n",
    "        # Create cache key\n",
    "        cache_key = f\"{params.ocr_model_name}_{params.line_mode}\"\n",
    "        \n",
    "        if cache_key not in self.pipelines:\n",
    "            ocr_model = self.ocr_models.get(params.ocr_model_name)\n",
    "            if not ocr_model:\n",
    "                raise ValueError(f\"OCR model not found: {params.ocr_model_name}\")\n",
    "            \n",
    "            line_config = self.line_config if params.line_mode == \"line\" else self.layout_config\n",
    "            \n",
    "            self.pipelines[cache_key] = OCRPipeline(\n",
    "                platform=self.platform,\n",
    "                ocr_config=ocr_model.config,\n",
    "                line_config=line_config\n",
    "            )\n",
    "        \n",
    "        return self.pipelines[cache_key]\n",
    "    \n",
    "    def run_ocr(self, image_path: Path, params: GridSearchParams) -> Tuple[bool, int, str, str, Dict]:\n",
    "        \"\"\"\n",
    "        Run OCR on a single image with given parameters.\n",
    "        \n",
    "        Returns: (success, num_lines, ocr_text, error_message, quality_metrics)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load image\n",
    "            image = cv2.imread(str(image_path))\n",
    "            if image is None:\n",
    "                return False, 0, \"\", f\"Failed to load image: {image_path}\", {}\n",
    "            \n",
    "            # Get pipeline\n",
    "            pipeline = self.get_pipeline(params)\n",
    "            \n",
    "            # Run OCR (use_tps always True, threshold controls behavior)\n",
    "            status, result = pipeline.run_ocr(\n",
    "                image=image,\n",
    "                k_factor=params.k_factor,\n",
    "                bbox_tolerance=params.bbox_tolerance,\n",
    "                merge_lines=params.merge_lines,\n",
    "                use_tps=True,  # Always True, threshold controls sensitivity\n",
    "                tps_threshold=params.tps_threshold,\n",
    "                target_encoding=Encoding.Unicode\n",
    "            )\n",
    "            \n",
    "            if status.name == \"SUCCESS\":\n",
    "                rot_mask, lines, ocr_lines, angle = result\n",
    "                text = \"\\n\".join([line.text for line in ocr_lines])\n",
    "                \n",
    "                # Score the OCR quality\n",
    "                quality_metrics = quality_scorer.score_text(text)\n",
    "                \n",
    "                return True, len(ocr_lines), text, \"\", quality_metrics\n",
    "            else:\n",
    "                return False, 0, \"\", str(result), {}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return False, 0, \"\", f\"{type(e).__name__}: {str(e)}\", {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868c955",
   "metadata": {
    "title": "Result Saving"
   },
   "outputs": [],
   "source": [
    "def save_result(\n",
    "    output_dir: Path,\n",
    "    file_name: str,\n",
    "    image_name: str,\n",
    "    params: GridSearchParams,\n",
    "    success: bool,\n",
    "    num_lines: int,\n",
    "    ocr_text: str,\n",
    "    error_message: str,\n",
    "    processing_time: float,\n",
    "    quality_metrics: Dict\n",
    "):\n",
    "    \"\"\"Save a single OCR result to a text file.\"\"\"\n",
    "    \n",
    "    # Create directory structure: output_dir/file_name/image_name/\n",
    "    result_dir = output_dir / file_name / image_name\n",
    "    result_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Generate filename from parameters\n",
    "    filename = params.to_filename() + \".txt\"\n",
    "    filepath = result_dir / filename\n",
    "    \n",
    "    # Build file content\n",
    "    content = []\n",
    "    content.append(\"=\" * 70)\n",
    "    content.append(\"OCR RESULT\")\n",
    "    content.append(\"=\" * 70)\n",
    "    content.append(f\"\")\n",
    "    content.append(f\"File: {file_name}\")\n",
    "    content.append(f\"Image: {image_name}\")\n",
    "    content.append(f\"\")\n",
    "    content.append(\"PARAMETERS:\")\n",
    "    content.append(f\"  OCR Model: {params.ocr_model_name}\")\n",
    "    content.append(f\"  Line Mode: {params.line_mode}\")\n",
    "    content.append(f\"  Class Threshold: {params.class_threshold}\")\n",
    "    content.append(f\"  K-Factor: {params.k_factor}\")\n",
    "    content.append(f\"  BBox Tolerance: {params.bbox_tolerance}\")\n",
    "    content.append(f\"  Merge Lines: {params.merge_lines}\")\n",
    "    content.append(f\"  TPS Threshold: {params.tps_threshold}\")\n",
    "    content.append(f\"\")\n",
    "    content.append(\"RESULTS:\")\n",
    "    content.append(f\"  Success: {success}\")\n",
    "    content.append(f\"  Lines Detected: {num_lines}\")\n",
    "    content.append(f\"  Processing Time: {processing_time:.2f}s\")\n",
    "    \n",
    "    # Add quality metrics\n",
    "    if quality_metrics:\n",
    "        content.append(f\"\")\n",
    "        content.append(\"QUALITY METRICS:\")\n",
    "        content.append(f\"  âœ¨ Quality Score: {quality_metrics.get('quality_score', 0):.2f}/100\")\n",
    "        content.append(f\"  Total Tokens: {quality_metrics.get('total_tokens', 0)}\")\n",
    "        content.append(f\"  Valid Words: {quality_metrics.get('valid_tokens', 0)}\")\n",
    "        content.append(f\"  Invalid Words: {quality_metrics.get('invalid_tokens', 0)}\")\n",
    "    \n",
    "    if error_message:\n",
    "        content.append(f\"  Error: {error_message}\")\n",
    "    content.append(f\"\")\n",
    "    content.append(\"=\" * 70)\n",
    "    content.append(\"OCR TEXT\")\n",
    "    content.append(\"=\" * 70)\n",
    "    content.append(f\"\")\n",
    "    content.append(ocr_text if ocr_text else \"[No text extracted]\")\n",
    "    \n",
    "    # Write file\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(content))\n",
    "\n",
    "\n",
    "def save_summary_csv(output_dir: Path, all_results: List[Dict]):\n",
    "    \"\"\"Save a summary CSV of all results for analysis.\"\"\"\n",
    "    \n",
    "    csv_path = output_dir / \"summary.csv\"\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"No results to save to summary\")\n",
    "        return\n",
    "    \n",
    "    # Get fieldnames from first result\n",
    "    fieldnames = list(all_results[0].keys())\n",
    "    \n",
    "    import csv\n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_results)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Summary CSV saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb3cbc",
   "metadata": {
    "title": "Main Grid Search Runner"
   },
   "outputs": [],
   "source": [
    "def run_grid_search(\n",
    "    max_images_per_file: int = None,\n",
    "    resume: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the full grid search.\n",
    "    \n",
    "    Args:\n",
    "        max_images_per_file: Limit images per file (for testing)\n",
    "        resume: Whether to resume from checkpoint (default True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize\n",
    "    checkpoint = CheckpointManager(CHECKPOINT_FILE)\n",
    "    ocr = GridSearchOCR()\n",
    "    all_results = []  # For summary CSV\n",
    "    \n",
    "    if resume and checkpoint.get_completed_count() > 0:\n",
    "        print(f\"\\nðŸ“‚ Resuming from checkpoint: {checkpoint.get_completed_count()} images already completed\")\n",
    "    elif not resume:\n",
    "        checkpoint.reset()\n",
    "        print(\"\\nðŸ”„ Starting fresh (checkpoint cleared)\")\n",
    "    \n",
    "    # Get test images\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"LOADING TEST IMAGES\")\n",
    "    print(\"=\" * 70)\n",
    "    images_by_file = get_all_test_images()\n",
    "    \n",
    "    # Calculate totals\n",
    "    total_images = sum(len(imgs) for imgs in images_by_file.values())\n",
    "    param_combinations = generate_param_combinations()\n",
    "    total_iterations = total_images * len(param_combinations)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(\"GRID SEARCH WITH QUALITY SCORING\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Total images: {total_images}\")\n",
    "    print(f\"Combinations per image: {len(param_combinations)}\")\n",
    "    print(f\"Total iterations: {total_iterations}\")\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Run with graceful interrupt handling\n",
    "    with GracefulInterrupt() as interrupt:\n",
    "        \n",
    "        # Progress tracking\n",
    "        images_processed = 0\n",
    "        images_skipped = 0\n",
    "        \n",
    "        for file_name, image_paths in sorted(images_by_file.items()):\n",
    "            if interrupt.interrupted:\n",
    "                break\n",
    "            \n",
    "            print(f\"\\nðŸ“ File: {file_name}\")\n",
    "            print(f\"   Images: {len(image_paths)}\")\n",
    "            \n",
    "            # Limit images if specified\n",
    "            if max_images_per_file:\n",
    "                image_paths = image_paths[:max_images_per_file]\n",
    "            \n",
    "            for image_path in image_paths:\n",
    "                if interrupt.interrupted:\n",
    "                    break\n",
    "                \n",
    "                image_key = str(image_path)\n",
    "                image_name = image_path.stem\n",
    "                \n",
    "                # Skip if already completed\n",
    "                if checkpoint.is_completed(image_key):\n",
    "                    images_skipped += 1\n",
    "                    continue\n",
    "                \n",
    "                print(f\"\\n   ðŸ–¼ï¸  Processing: {image_name}\")\n",
    "                \n",
    "                # Progress bar for this image's combinations\n",
    "                pbar = tqdm(\n",
    "                    param_combinations, \n",
    "                    desc=f\"      Params\",\n",
    "                    leave=False\n",
    "                )\n",
    "                \n",
    "                for params in pbar:\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    # Run OCR\n",
    "                    success, num_lines, ocr_text, error, quality_metrics = ocr.run_ocr(image_path, params)\n",
    "                    \n",
    "                    processing_time = time.time() - start_time\n",
    "                    \n",
    "                    # Save individual result file\n",
    "                    save_result(\n",
    "                        output_dir=OUTPUT_DIR,\n",
    "                        file_name=file_name,\n",
    "                        image_name=image_name,\n",
    "                        params=params,\n",
    "                        success=success,\n",
    "                        num_lines=num_lines,\n",
    "                        ocr_text=ocr_text,\n",
    "                        error_message=error,\n",
    "                        processing_time=processing_time,\n",
    "                        quality_metrics=quality_metrics\n",
    "                    )\n",
    "                    \n",
    "                    # Add to summary\n",
    "                    all_results.append({\n",
    "                        \"file_name\": file_name,\n",
    "                        \"image_name\": image_name,\n",
    "                        \"ocr_model_name\": params.ocr_model_name,\n",
    "                        \"line_mode\": params.line_mode,\n",
    "                        \"class_threshold\": params.class_threshold,\n",
    "                        \"k_factor\": params.k_factor,\n",
    "                        \"bbox_tolerance\": params.bbox_tolerance,\n",
    "                        \"merge_lines\": params.merge_lines,\n",
    "                        \"tps_threshold\": params.tps_threshold,\n",
    "                        \"success\": success,\n",
    "                        \"num_lines_detected\": num_lines,\n",
    "                        \"processing_time\": processing_time,\n",
    "                        \"quality_score\": quality_metrics.get('quality_score', 0.0),\n",
    "                        \"total_tokens\": quality_metrics.get('total_tokens', 0),\n",
    "                        \"valid_tokens\": quality_metrics.get('valid_tokens', 0),\n",
    "                        \"invalid_tokens\": quality_metrics.get('invalid_tokens', 0),\n",
    "                        \"error\": error[:100] if error else \"\"\n",
    "                    })\n",
    "                \n",
    "                pbar.close()\n",
    "                \n",
    "                # Mark image as completed\n",
    "                checkpoint.mark_completed(image_key)\n",
    "                images_processed += 1\n",
    "                print(f\"      âœ… Completed ({images_processed} processed, {images_skipped} skipped)\")\n",
    "        \n",
    "        # Save summary CSV\n",
    "        save_summary_csv(OUTPUT_DIR, all_results)\n",
    "    \n",
    "    # Final status\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    if interrupt.interrupted:\n",
    "        print(\"âš ï¸  INTERRUPTED - Progress saved, run again to resume\")\n",
    "    else:\n",
    "        print(\"âœ… GRID SEARCH COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Images processed this run: {images_processed}\")\n",
    "    print(f\"Images skipped (from checkpoint): {images_skipped}\")\n",
    "    print(f\"Results saved to: {OUTPUT_DIR}\")\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4ec97",
   "metadata": {
    "title": "Analysis Helper"
   },
   "outputs": [],
   "source": [
    "def analyze_results():\n",
    "    \"\"\"Load and analyze results from the summary CSV with quality scores.\"\"\"\n",
    "    \n",
    "    csv_path = OUTPUT_DIR / \"summary.csv\"\n",
    "    \n",
    "    if not csv_path.exists():\n",
    "        print(\"âŒ No summary.csv found. Run grid search first.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        import pandas as pd\n",
    "    except ImportError:\n",
    "        print(\"âŒ pandas required for analysis. Install with: pip install pandas\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ANALYSIS RESULTS WITH QUALITY SCORES\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nTotal results: {len(df)}\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š Success Rate by OCR Model:\")\n",
    "    print(df.groupby('ocr_model_name')['success'].mean().sort_values(ascending=False))\n",
    "    \n",
    "    print(\"\\nâœ¨ Average Quality Score by OCR Model:\")\n",
    "    successful = df[df['success'] == True]\n",
    "    if len(successful) > 0:\n",
    "        print(successful.groupby('ocr_model_name')['quality_score'].mean().sort_values(ascending=False))\n",
    "    \n",
    "    print(\"\\nðŸ“Š Success Rate by Line Mode:\")\n",
    "    print(df.groupby('line_mode')['success'].mean())\n",
    "    \n",
    "    print(\"\\nâœ¨ Average Quality Score by Line Mode:\")\n",
    "    if len(successful) > 0:\n",
    "        print(successful.groupby('line_mode')['quality_score'].mean())\n",
    "    \n",
    "    print(\"\\nðŸ“Š Success Rate by K-Factor:\")\n",
    "    print(df.groupby('k_factor')['success'].mean())\n",
    "    \n",
    "    print(\"\\nâœ¨ Average Quality Score by K-Factor:\")\n",
    "    if len(successful) > 0:\n",
    "        print(successful.groupby('k_factor')['quality_score'].mean())\n",
    "    \n",
    "    # Top 10 parameter combinations by quality score\n",
    "    print(\"\\nðŸ† TOP 10 PARAMETER COMBINATIONS (by quality score):\")\n",
    "    if len(successful) > 0:\n",
    "        top_10 = successful.nlargest(10, 'quality_score')[\n",
    "            ['file_name', 'image_name', 'ocr_model_name', 'line_mode', \n",
    "             'k_factor', 'bbox_tolerance', 'quality_score', 'num_lines_detected']\n",
    "        ]\n",
    "        print(top_10.to_string(index=False))\n",
    "    \n",
    "    # Quality score distribution\n",
    "    print(\"\\nðŸ“Š Quality Score Distribution:\")\n",
    "    print(f\"  >90 (Excellent):  {len(df[df['quality_score'] > 90])}\")\n",
    "    print(f\"  70-90 (Good):     {len(df[(df['quality_score'] >= 70) & (df['quality_score'] <= 90)])}\")\n",
    "    print(f\"  50-70 (Fair):     {len(df[(df['quality_score'] >= 50) & (df['quality_score'] < 70)])}\")\n",
    "    print(f\"  <50 (Poor):       {len(df[df['quality_score'] < 50])}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a93e7c",
   "metadata": {
    "title": "Quick Test"
   },
   "outputs": [],
   "source": [
    "def quick_test():\n",
    "    \"\"\"Run a quick test with 1 image, limited params.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"QUICK TEST\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Running with 1 image to verify setup...\")\n",
    "    \n",
    "    # Clear checkpoint for fresh test\n",
    "    checkpoint = CheckpointManager(CHECKPOINT_FILE)\n",
    "    checkpoint.reset()\n",
    "    \n",
    "    results = run_grid_search(\n",
    "        max_images_per_file=1,\n",
    "        resume=False\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b7e8dd",
   "metadata": {
    "title": "1. QUICK TEST - Run this first to verify setup"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runs 1 image with all parameter combinations.\n",
    "Use this to verify everything works before the full run.\n",
    "\"\"\"\n",
    "# quick_test_results = quick_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb4bd2",
   "metadata": {
    "title": "2. FULL GRID SEARCH - Main run (resume-able)"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runs all images with all parameter combinations.\n",
    "- Automatically resumes from checkpoint if interrupted\n",
    "- Press Ctrl+C to stop gracefully (finishes current image)\n",
    "- Run this cell again to continue where you left off\n",
    "\"\"\"\n",
    "# full_results = run_grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f90c7",
   "metadata": {
    "title": "3. ANALYZE RESULTS - View summary statistics"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loads the summary.csv and shows statistics including quality scores.\n",
    "Run this after the grid search completes (or partially completes).\n",
    "\"\"\"\n",
    "# df = analyze_results()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
